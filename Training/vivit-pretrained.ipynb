{"cells":[{"cell_type":"code","source":["!pip install transformers\n","!pip install accelerate"],"metadata":{"id":"r7MhOPd9cO9J"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"FNebXzHz5-cL"},"outputs":[],"source":["!pip install --upgrade keras\n","!pip install albumentations"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":16326,"status":"ok","timestamp":1716397722883,"user":{"displayName":"Tomas Kondrotas","userId":"11426183563726409011"},"user_tz":-180},"id":"G1gEQUW6BoZV","outputId":"bf933087-68fc-4101-ebe1-97c790dc297f"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","\n","# Mount Google Drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":true,"id":"-VocpoXwCJQb"},"outputs":[],"source":["!unzip \"/content/drive/MyDrive/Bakis/cnnlstm/split.zip\" -d \"/content/dataset\""]},{"cell_type":"code","execution_count":null,"metadata":{"id":"UrS9w0skoFQi"},"outputs":[],"source":["import os\n","import io\n","import imageio\n","import pandas as pd\n","import ipywidgets\n","import numpy as np\n","import tensorflow as tf  # for data preprocessing only\n","import keras\n","from keras import layers, ops\n","import cv2\n","from sklearn.preprocessing import LabelEncoder\n","import albumentations as A\n","import random"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_8l9H0v8CuI3"},"outputs":[],"source":["grab_frames = 32\n","target_shape = 224"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"efN2WfPQDBkl"},"outputs":[],"source":["train_dir = '/content/dataset/training'\n","test_dir = '/content/dataset/test'\n","val_dir = '/content/dataset/validation'"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"o76dHNklGibX"},"outputs":[],"source":["labels = np.array(['aciu', 'berniukas', 'kamuolys', 'koks', 'labas', 'mama', 'namas', 'tevas', 'valgyti', 'vardas'])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"TvjbNAshBPeF"},"outputs":[],"source":["def process_dataset(train_dir, set_size, augment=False):\n","    X_data = np.zeros((set_size, grab_frames, target_shape, target_shape, 3), dtype=np.uint8)\n","    y_temp = np.zeros((set_size,), dtype=object)\n","\n","    index = 0\n","    random.seed(7)\n","\n","    transform = A.ReplayCompose([\n","      A.HorizontalFlip(p=0.5),\n","      A.MotionBlur(blur_limit=5, p=0.3),\n","      A.ShiftScaleRotate(shift_limit=0.02, scale_limit=0.02, rotate_limit=10, p=0.5),\n","      A.RandomBrightnessContrast(brightness_limit=0.1, contrast_limit=0.1, p=0.4),\n","      A.CLAHE(clip_limit=2, p=0.3),\n","      A.HueSaturationValue(hue_shift_limit=10, sat_shift_limit=20, val_shift_limit=10, p=0.3),\n","      A.ISONoise(color_shift=(0.01, 0.03), intensity=(0.1, 0.3), p=0.3),\n","    ])\n","\n","    data = []\n","\n","    source_directory = os.path.abspath(train_dir)\n","    sub_folders = os.listdir(source_directory)\n","\n","    for folder in sub_folders:\n","        folder_path = os.path.join(source_directory, folder)\n","        files = os.listdir(folder_path)\n","\n","        for file in files:\n","\n","            video_path = os.path.join(folder_path, file)\n","            video = cv2.VideoCapture(video_path)\n","            frames = []\n","            framesAug = []\n","            count = 1\n","            lastFrame = None\n","            skip = False\n","\n","            while count <= grab_frames:\n","                ret, frame = video.read()\n","                if not ret:\n","                    break\n","\n","                if skip == True:\n","                  skip = not skip\n","                  continue\n","\n","                frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n","                frame = cv2.resize(frame, (target_shape, target_shape))\n","                lastFrame = frame\n","\n","                if augment != True:\n","                  frames.append(frame)\n","\n","                count += 1\n","\n","                if augment:\n","                  if data == []:\n","                    data = transform(image=frame)\n","                    framesAug.append(data['image'])\n","                  else:\n","                    augImg = A.ReplayCompose.replay(data['replay'], image=frame)\n","                    framesAug.append(augImg['image'])\n","\n","                skip = not skip\n","\n","            video.release()\n","            cv2.destroyAllWindows()\n","\n","            if augment != True:\n","              X_data[index] = np.array(frames)\n","              y_temp[index] = folder\n","              index += 1\n","            if augment:\n","              X_data[index] = np.array(framesAug)\n","              y_temp[index] = folder\n","              index += 1\n","              data = []\n","            print(index)\n","\n","\n","    return X_data, y_temp"]},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":true,"id":"GhiqTlalDDsQ"},"outputs":[],"source":["X_train, y_train = process_dataset(train_dir, 2100, True)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"crd94fNi-7d7"},"outputs":[],"source":["X_valid, y_valid = process_dataset(val_dir, 200)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"DtGXhHoU_Ts1"},"outputs":[],"source":["X_test, y_test = process_dataset(test_dir, 200)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"kYiLH73VHS7D"},"outputs":[],"source":["le = LabelEncoder()\n","\n","# Fit the encoder on the labels array\n","le.fit(labels)  # Learning the mapping from the labels array\n","\n","# Transform the dataset using the learned encoder\n","y_train = le.transform(y_train)\n","y_valid = le.transform(y_valid)\n","y_test = le.transform(y_test)"]},{"cell_type":"code","source":["import numpy as np\n","from sklearn.metrics import accuracy_score\n","\n","def compute_metrics(eval_pred):\n","    logits, labels = eval_pred\n","    predictions = np.argmax(logits, axis=1)\n","    accuracy = accuracy_score(labels, predictions)\n","    return {\"accuracy\": accuracy}"],"metadata":{"id":"_Wn-Ti1eR6xp"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import torch\n","from torch.utils.data import Dataset, DataLoader\n","from transformers import VivitForVideoClassification, VivitImageProcessor, TrainingArguments, Trainer\n","from PIL import Image\n","import numpy as np\n","\n","class CustomVideoDataset(Dataset):\n","    def __init__(self, videos, labels):\n","        self.videos = videos\n","        self.labels = labels\n","\n","    def __len__(self):\n","        return len(self.videos)\n","\n","    def __getitem__(self, idx):\n","        video = self.videos[idx]\n","        label = self.labels[idx]\n","        # Convert numpy arrays to PIL images\n","        video_frames = [Image.fromarray(frame.astype('uint8')) for frame in video]\n","        return video_frames, label\n","\n","train_dataset = CustomVideoDataset(X_train, y_train)\n","val_dataset = CustomVideoDataset(X_valid, y_valid)\n","\n","train_dataloader = DataLoader(train_dataset, batch_size=8, shuffle=True)\n","val_dataloader = DataLoader(val_dataset, batch_size=8)\n","\n","\n","model = VivitForVideoClassification.from_pretrained('google/vivit-b-16x2')\n","processor = VivitImageProcessor.from_pretrained('google/vivit-b-16x2')\n","\n","def preprocess_function(videos):\n","    inputs = processor(videos, return_tensors=\"pt\")\n","    return inputs\n","\n","def collate_fn(batch):\n","    videos, labels = zip(*batch)\n","    inputs = preprocess_function(videos)\n","    inputs['labels'] = torch.tensor(labels)\n","    return inputs\n","\n","training_args = TrainingArguments(\n","    output_dir='./results',\n","    num_train_epochs=2,\n","    per_device_train_batch_size=1,\n","    per_device_eval_batch_size=1,\n","    warmup_steps=500,\n","    weight_decay=0.01,\n","    logging_dir='./logs',\n","    logging_steps=10,\n","    evaluation_strategy=\"epoch\",\n","    save_strategy=\"epoch\",\n","    save_total_limit=1,\n","    load_best_model_at_end=True,\n","    fp16=True,\n",")\n","\n","trainer = Trainer(\n","    model=model,\n","    args=training_args,\n","    train_dataset=train_dataset,\n","    eval_dataset=val_dataset,\n","    data_collator=collate_fn,\n","    compute_metrics=compute_metrics\n",")\n","\n","torch.cuda.empty_cache()\n","trainer.train()"],"metadata":{"id":"CdfD22trEnIZ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["test_dataset = CustomVideoDataset(X_test, y_test)\n","test_dataloader = DataLoader(test_dataset, batch_size=8)"],"metadata":{"id":"w4h-Lc9DYvG9"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["metrics = trainer.evaluate(eval_dataset=test_dataset)\n","print(metrics)"],"metadata":{"id":"_T0hkDcSYz4H"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"aRUqQKpnx_4d"},"outputs":[],"source":["from google.colab import runtime\n","runtime.unassign()"]}],"metadata":{"colab":{"provenance":[],"gpuType":"L4","authorship_tag":"ABX9TyPbMWuyte2keYZYzcgbHb9K"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":0}